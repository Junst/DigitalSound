{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7prG1BISon3O"
      },
      "source": [
        "# **Urban Sound Classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "x-hwpq6don3V"
      },
      "outputs": [],
      "source": [
        "import IPython.display as ipd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "hF0yA7aUon3o"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9D6ifd1uon3Y",
        "outputId": "dfcf718c-4d98-4f7f-8b0d-e5c6f9baee6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>siren</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>street_music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>drilling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>siren</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5430</th>\n",
              "      <td>8725</td>\n",
              "      <td>engine_idling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5431</th>\n",
              "      <td>8726</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5432</th>\n",
              "      <td>8727</td>\n",
              "      <td>engine_idling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5433</th>\n",
              "      <td>8728</td>\n",
              "      <td>engine_idling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5434</th>\n",
              "      <td>8729</td>\n",
              "      <td>air_conditioner</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5435 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        ID            Class\n",
              "0        0            siren\n",
              "1        1     street_music\n",
              "2        2         drilling\n",
              "3        3            siren\n",
              "4        4         dog_bark\n",
              "...    ...              ...\n",
              "5430  8725    engine_idling\n",
              "5431  8726         dog_bark\n",
              "5432  8727    engine_idling\n",
              "5433  8728    engine_idling\n",
              "5434  8729  air_conditioner\n",
              "\n",
              "[5435 rows x 2 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/data/'\n",
        "#path = 'D:\\data/'\n",
        "path_train = '/content/drive/MyDrive/Colab Notebooks/data/Train/'\n",
        "df = pd.read_csv(path + 'train.csv')\n",
        "test_df = pd.read_csv(path + 'test.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p61a6VUKqTfp",
        "outputId": "38d86a35-9604-453d-b5ff-e1ba7491e4e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0EWgsGK7-da"
      },
      "source": [
        "# **데이터 전처리**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxrZb1xI8BtQ"
      },
      "source": [
        "**범주형(Categorical) 데이터셋으로 변환**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "o1uBrIqton3g",
        "outputId": "758017d5-c87c-4764-9f0d-364124ba872c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Class</th>\n",
              "      <th>numeric_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>siren</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>street_music</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>drilling</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>siren</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>dog_bark</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5430</th>\n",
              "      <td>8725</td>\n",
              "      <td>engine_idling</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5431</th>\n",
              "      <td>8726</td>\n",
              "      <td>dog_bark</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5432</th>\n",
              "      <td>8727</td>\n",
              "      <td>engine_idling</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5433</th>\n",
              "      <td>8728</td>\n",
              "      <td>engine_idling</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5434</th>\n",
              "      <td>8729</td>\n",
              "      <td>air_conditioner</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5435 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        ID            Class  numeric_class\n",
              "0        0            siren              8\n",
              "1        1     street_music              9\n",
              "2        2         drilling              4\n",
              "3        3            siren              8\n",
              "4        4         dog_bark              3\n",
              "...    ...              ...            ...\n",
              "5430  8725    engine_idling              5\n",
              "5431  8726         dog_bark              3\n",
              "5432  8727    engine_idling              5\n",
              "5433  8728    engine_idling              5\n",
              "5434  8729  air_conditioner              0\n",
              "\n",
              "[5435 rows x 3 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Converting classes into numeric format\n",
        "df['numeric_class'] = df['Class'].astype('category').cat.codes\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u60fDFm8G-K"
      },
      "source": [
        "**Train Dataset과 Validation Dataset으로 나누기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "9yzjsK26on3i"
      },
      "outputs": [],
      "source": [
        "def train_val_split(df):\n",
        "    train_df = pd.DataFrame(columns = df.columns)\n",
        "    val_df = pd.DataFrame(columns = df.columns)\n",
        "\n",
        "    train_df = df[:int(df['ID'].count()*0.8)]\n",
        "    val_df = df[4348:]\n",
        "        \n",
        "    return train_df, val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL5PzG3won3k",
        "outputId": "99a70526-ef67-471a-9e3b-8bd8dbfe382d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4348, 3), (1087, 3))"
            ]
          },
          "execution_count": 48,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df, val_df = train_val_split(df)\n",
        "train_df.shape, val_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipmnop1f8MzH"
      },
      "source": [
        "**진행 시각화(Visualization)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "XWwFgp2e21N0"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import sys\n",
        "\n",
        "def drawProgressBar(current, total, string = '', barLen = 20):\n",
        "\n",
        "    percent = current/total\n",
        "    arrow = \">\"\n",
        "    if percent == 1:\n",
        "        arrow = \"\"\n",
        "   \n",
        "    sys.stdout.write(\"\\r\")\n",
        "    sys.stdout.write(\"Progress: [{:<{}}] {}/{}\".format(\"=\" * int(barLen * percent) + arrow, \n",
        "                                                         barLen, current, total) + string)\n",
        "    sys.stdout.flush()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvD10v7P8VM-"
      },
      "source": [
        "**동일한 크기의 오디오 클립 만들기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "9TvDth2Non3Z"
      },
      "outputs": [],
      "source": [
        "def get_audio_same_len(wav, sr):\n",
        "    if wav.shape[0] < 4 * sr:\n",
        "        wav = np.pad(wav, int(np.ceil((4 * sr - wav.shape[0])/2)), mode = 'reflect')\n",
        "    wav = wav[:4 * sr]\n",
        "    \n",
        "    return wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgIWXws_8Yjd"
      },
      "source": [
        "**스펙트로그램 만들기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "z60h9Qn-on3a"
      },
      "outputs": [],
      "source": [
        "def get_melspectrogram_db(wav, sr):\n",
        "  \n",
        "    wav = get_audio_same_len(wav, sr)\n",
        "        \n",
        "    spec = librosa.feature.melspectrogram(wav, sr, n_fft = 2048, hop_length = 512, \n",
        "                          n_mels = 128, fmin = 20, fmax = 8300)\n",
        "    \n",
        "    spec = librosa.power_to_db(spec, top_db = 80)\n",
        "    return spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv3i4Jff8fe7"
      },
      "source": [
        "**표준화와 정규화**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "RQNJmNrvGIFe"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def standard_norm(spec):\n",
        "    mMscaler = MinMaxScaler()\n",
        "    sdscaler = StandardScaler()\n",
        "\n",
        "    spec = sdscaler.fit_transform(spec)\n",
        "    spec = mMscaler.fit_transform(spec)\n",
        "    spec_scaled = spec*255\n",
        "\n",
        "    return spec_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "hqNV-gPEon3p"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7P-Ro5Q8pYa"
      },
      "source": [
        "**음성 데이터 로딩(loading)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "fUv3vzNqon3p"
      },
      "outputs": [],
      "source": [
        "def load_data(df):\n",
        "    audio_data = []\n",
        "    sample_rates = []\n",
        "    labels = []\n",
        "    \n",
        "    tot = len(df)\n",
        "    curr = 0\n",
        "    \n",
        "    for idx in df.index:\n",
        "        try:\n",
        "            file_name = str(df['ID'][idx]) + '.wav'\n",
        "            wav, sr = librosa.load('/content/drive/MyDrive/Colab Notebooks/data/Train/' + file_name)\n",
        "            \n",
        "            wav = get_audio_same_len(wav, sr)\n",
        "    \n",
        "            audio_data.append(wav)\n",
        "            sample_rates.append(sr)\n",
        "            \n",
        "            labels.append(df['numeric_class'][idx])\n",
        "            \n",
        "            curr += 1\n",
        "            drawProgressBar(curr, tot, barLen = 40)\n",
        "        \n",
        "        except KeyboardInterrupt:\n",
        "            print('KeyBoardInterrupt')\n",
        "            break\n",
        "        \n",
        "        except Exception:\n",
        "            print(\"Couldn't read file\", df['ID'][idx])\n",
        "            curr += 1\n",
        "            \n",
        "    print('\\n')\n",
        "    return np.stack(audio_data, axis = 0), np.array(sample_rates), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3j52YKYon3q",
        "outputId": "5fa75003-e101-46b8-cbf4-9d955e967122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: [========================================] 4348/4348\n",
            "\n",
            "Progress: [========================================] 1087/1087\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_data, train_sr, train_labels = load_data(train_df)\n",
        "val_data, val_sr, val_labels = load_data(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mvq55ELOon3r",
        "outputId": "a1478632-5aa7-4716-cea9-6064ae3be0e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((4348, 88200), (1087, 88200))"
            ]
          },
          "execution_count": 56,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.shape, val_data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_vIaikx81Gx"
      },
      "source": [
        "**데이터 변환(Coversion)과 Tensor Dataset 구축**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "zhfmGIhVon3s"
      },
      "outputs": [],
      "source": [
        "# Convert numpy arrays to torch tensors\n",
        "train_data = torch.from_numpy(train_data)\n",
        "train_labels = torch.from_numpy(train_labels).long()\n",
        "\n",
        "val_data = torch.from_numpy(val_data)\n",
        "val_labels = torch.from_numpy(val_labels).long()\n",
        "\n",
        "# Create data loaders\n",
        "train_data = data_utils.TensorDataset(train_data, train_labels)\n",
        "val_data = data_utils.TensorDataset(val_data, val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G70cw58yon3u"
      },
      "source": [
        "## **Convolutional Neural Network(CNN)** on Spectrogram Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjVw5Fjjon3u",
        "outputId": "31e4fa8e-198e-4dd4-e9cd-87b2e85adf74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({22050}, {22050})"
            ]
          },
          "execution_count": 58,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(train_sr), set(val_sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "2PM54NWmon3w"
      },
      "outputs": [],
      "source": [
        "train_sr = 22050\n",
        "val_sr = 22050"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBI3mSShAmRB"
      },
      "source": [
        "**DataLoader 구축하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "x_T_W_w8on3w"
      },
      "outputs": [],
      "source": [
        "def get_spectrogram_loader(audio_data, sr, batch_size, shuffle = False):\n",
        "\n",
        "    hop_length = 512 # 샘플의 수\n",
        "    n_fft = 2048 # 윈도우 # spectral resolution / window length\n",
        "\n",
        "    audio_spec_img = []\n",
        "    labels = []\n",
        "    curr = 0\n",
        "    tot = len(audio_data)\n",
        "\n",
        "    for wav, label in audio_data:\n",
        "        spec_img = standard_norm(get_melspectrogram_db(wav.numpy(), sr))\n",
        "        spec_img = np.expand_dims(spec_img, axis = 0)\n",
        "        audio_spec_img.append(spec_img)\n",
        "        labels.append(label)\n",
        "\n",
        "        curr += 1\n",
        "        drawProgressBar(curr, tot, barLen = 40)\n",
        "\n",
        "    audio_spec_img = torch.Tensor(audio_spec_img)\n",
        "    audio_spec_img = audio_spec_img / 255\n",
        "    \n",
        "    labels = torch.Tensor(labels).long()\n",
        "\n",
        "    audio_spec_img = data_utils.TensorDataset(audio_spec_img, labels)\n",
        "    #audio_loader = data_utils.DataLoader(audio_spec_img, batch_size = batch_size, shuffle = shuffle)\n",
        "    \n",
        "    #return audio_loader\n",
        "    return audio_spec_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoC6gbwMon3x",
        "outputId": "a15c7ad9-bfc9-48cf-ebda-e9ffff6baa87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: [========================================] 4348/4348"
          ]
        }
      ],
      "source": [
        "train_spec_dataset = get_spectrogram_loader(train_data, train_sr, BATCH_SIZE, shuffle = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrGFtjkQF18A",
        "outputId": "c779012d-1a5a-42f2-ee6c-ad1572fba18a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 173])"
            ]
          },
          "execution_count": 101,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_spec_dataset[0][0].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "FkNH9AUS_vf3"
      },
      "outputs": [],
      "source": [
        "train_loader = data_utils.DataLoader(train_spec_dataset, batch_size = BATCH_SIZE, shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3px0kV9on3y",
        "outputId": "0042d865-56a3-45f6-bdb0-ba2bbce6a9fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: [========================================] 1087/1087"
          ]
        }
      ],
      "source": [
        "val_spec_dataset  = get_spectrogram_loader(val_data, val_sr, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0-Fh207AVE-",
        "outputId": "f705c365-2553-4eec-c4bc-e0b98ca28f75"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 173])"
            ]
          },
          "execution_count": 104,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_spec_dataset[0][0].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "a_wLVJpCAXfb"
      },
      "outputs": [],
      "source": [
        "val_loader = data_utils.DataLoader(train_spec_dataset, batch_size = BATCH_SIZE, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK92j_VPAowA"
      },
      "source": [
        "**CNN 모델 구축하기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A-0cxDLHZmA",
        "outputId": "90c38c12-1b9f-4c2a-cf37-fd5d5ba930e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 62, 84])"
            ]
          },
          "execution_count": 186,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 파라미터 설정 방법\n",
        "input = torch.Tensor(1,1,128,173)\n",
        "conv1 = nn.Conv2d(1, 8, (5, 6))\n",
        "pool =  nn.MaxPool2d(2)\n",
        "out=conv1(input)\n",
        "out=pool(out)\n",
        "\n",
        "out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "5xU0fS3Pon30"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 10\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        \n",
        "        # Layer 1, Input shape (1, 128, 173) ->  Output shape (8, 62, 84)\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = (5, 6)), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(kernel_size = (2, 2)))\n",
        "        \n",
        "        # Layer 2, Input shape (8, 62, 84) -> Output shape (16, 30, 41)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = (3, 3)), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(kernel_size = (2, 2)))\n",
        "        \n",
        "        # Layer 3, Input shape (16, 30, 41) -> Output shape (64, 10, 15)\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = (6, 7)), \n",
        "            nn.ReLU(), \n",
        "            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = (6, 6)), \n",
        "            nn.ReLU(), \n",
        "            nn.MaxPool2d(kernel_size = (2, 2)))\n",
        "        \n",
        "        # Fully Connected layer 1, Input features 64 * 10 * 15 -> Output features 512\n",
        "        self.fc1 = nn.Linear(in_features = 64 * 10 * 15, out_features = 512)\n",
        "        \n",
        "        # Fully Connected layer 2, Input features 512 -> Output features 256\n",
        "        self.fc2 = nn.Linear(in_features = 512, out_features = 256)\n",
        "        \n",
        "        # Fully Connected layer 3, Input features 256 -> Output features 128\n",
        "        self.fc3 = nn.Linear(in_features = 256, out_features = 128)\n",
        "        \n",
        "        # Fully Connected layer 4, Input features 128 -> Output features 10\n",
        "        self.fc4 = nn.Linear(in_features = 128, out_features = NUM_CLASSES)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        n_features = 1\n",
        "        for s in size:\n",
        "            n_features = n_features * s\n",
        "        \n",
        "        return n_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFHouSPHAyWM"
      },
      "source": [
        "**CNN 클래스 불러오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "zBFdhu0son31"
      },
      "outputs": [],
      "source": [
        "model = ConvNet()\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsV4nhxqA2CW"
      },
      "source": [
        "**학습(Training)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlFhmw59on33",
        "outputId": "c0b90cd8-af07-49dd-dc8d-3d36c69fd500"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:\n",
            "Progress: [====================] 136/136\t loss: 1.7394 \t acc: 0.2857\n",
            "\n",
            "\n",
            "Epoch 2:\n",
            "Progress: [====================] 136/136\t loss: 1.5513 \t acc: 0.5000\n",
            "\n",
            "\n",
            "Epoch 3:\n",
            "Progress: [====================] 136/136\t loss: 1.1755 \t acc: 0.6429\n",
            "\n",
            "\n",
            "Epoch 4:\n",
            "Progress: [====================] 136/136\t loss: 0.9580 \t acc: 0.6786\n",
            "\n",
            "\n",
            "Epoch 5:\n",
            "Progress: [====================] 136/136\t loss: 0.8415 \t acc: 0.8214\n",
            "\n",
            "\n",
            "Epoch 6:\n",
            "Progress: [====================] 136/136\t loss: 0.6005 \t acc: 0.8571\n",
            "\n",
            "\n",
            "Epoch 7:\n",
            "Progress: [====================] 136/136\t loss: 0.6528 \t acc: 0.8214\n",
            "\n",
            "\n",
            "Epoch 8:\n",
            "Progress: [====================] 136/136\t loss: 0.3204 \t acc: 0.9286\n",
            "\n",
            "\n",
            "Epoch 9:\n",
            "Progress: [====================] 136/136\t loss: 0.3002 \t acc: 0.8929\n",
            "\n",
            "\n",
            "Epoch 10:\n",
            "Progress: [====================] 136/136\t loss: 0.1883 \t acc: 0.9286\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "THRESHOLD = 0.001 \n",
        "num_train_batches = len(train_loader)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"Epoch \" + str(epoch + 1) + \":\")\n",
        "    \n",
        "    for i, batch in enumerate(train_loader):\n",
        "        \n",
        "        data, labels = batch\n",
        "        \n",
        "        outputs = model(data)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs, dim = 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        accuracy = correct / total\n",
        "        \n",
        "        drawProgressBar((i + 1), num_train_batches, \n",
        "                              '\\t loss: {:.4f} \\t acc: {:.4f}'.format(round(loss.item(), 4), round(accuracy, 4)))\n",
        "    \n",
        "    print('\\n\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMIHpmXKA-Qf"
      },
      "source": [
        "**평가**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "XezvIqL4on3t"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, test_loader):\n",
        "\n",
        "    model.eval()\n",
        "    num_test_batches = len(test_loader)\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        total_loss = 0\n",
        "        for i, batch in enumerate(test_loader):\n",
        "            inputs, labels = batch\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, dim = 1)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            drawProgressBar((i+1), num_test_batches)\n",
        "        \n",
        "        accuracy = correct/total\n",
        "        test_loss = total_loss/num_test_batches\n",
        "    \n",
        "    return accuracy, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVQiqJGhon35",
        "outputId": "7412f584-e953-4136-a36f-f54e807336ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: [====================] 136/136\n",
            "\n",
            "Validation accuracy: 0.9121\n",
            "Validation loss: 0.2446\n"
          ]
        }
      ],
      "source": [
        "val_acc, val_loss = evaluate(model, val_loader)\n",
        "\n",
        "print(\"\\n\\nValidation accuracy: {:.4f}\".format(round(val_acc, 4)))\n",
        "print(\"Validation loss: {:.4f}\".format(round(val_loss, 4)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "usc_cnn_test_ex.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
